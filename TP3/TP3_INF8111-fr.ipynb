{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5fHWJhwOXGzh"
   },
   "source": [
    "# INF8111 - Fouille de données \n",
    "## Été 2020 - TP3 - Fouille de réseaux sociaux\n",
    "### Membres de l'équipe\n",
    "    - Membre 1\n",
    "    - Membre 2\n",
    "    - Membre 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TmGvqtSVgfXi"
   },
   "source": [
    "## Directives de remise\n",
    "Le travail sera réalisé avec la  même équipe que pour les TPs précédents. \n",
    "Vous devez remettre dans la boîte de remise sur moodle:\n",
    "\n",
    "1. ce fichier nommé TP3\\_NomDuMembre1\\_NomDuMembre2\\_NomDuMembre3.ipynb\n",
    "\n",
    "**N.B**: Assurez-vous que tous les résultats sont lisibles lorsque le notebook est ouvert.\n",
    "\n",
    "Tout devra être remis avant le **20 juin 2020 à 23h55**. Tout travail en retard sera pénalisé d’une valeur de 10\\% par jour de retard.\n",
    "\n",
    "## Barème\n",
    "Partie 1: 12 points\n",
    "\n",
    "Partie 2: 8 points\n",
    "\n",
    "Pour un total de 20 points sur 20 points.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P1et8f3nXGzk"
   },
   "source": [
    "## Réseaux sociaux\n",
    "Les réseaux sociaux occupent une grande partie de la vie humaine. Chaque personne appartient tout le long de sa vie à différentes communautés. Avec le rassemblage de ces informations sur les différentes plateformes en ligne de réseaux sociaux, les analystes de données ont voulu exploiter ces données. C'est un domaine relativement nouveau qui est en pleine croissance avec plusieurs impacts sur plusieurs aspects tels que la publicité et les systèmes de recommandation. \n",
    "\n",
    "### But\n",
    "Le but de ce TP est de vous donner un aperçu de l'analyse d'un réseau social.\n",
    "\n",
    "Dans la première partie, vous implémenterez un algorithme de détection de communautés dans un réseau social nommé LPAm+. Cet algorithme a été proposé par [X. Liu et T. Murata en 2010](https://www.sciencedirect.com/science/article/pii/S0378437109010152).\n",
    "\n",
    "Dans la deuxième partie, vous trouverez les personnes avec le plus d'influence dans leur réseau social. \n",
    "\n",
    "Pour les deux parties, nous vous fournissons les csv contenant les réseaux sociaux à analyser.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "517JwzlPXGzp"
   },
   "source": [
    "# 1. LPAm+ (12 points)\n",
    "\n",
    "## Détection de communauté\n",
    "La détection de communauté dans un réseau social est une manipulation fréquente lors de l'analyse d'un réseau. Une méthode de clustering est utilisée pour rassembler les personnes dans des communautés selon les liens entre eux. \n",
    "\n",
    "## LPAm+\n",
    "Dans cette partie, vous implémenterez l'algorithme LPAm+ pour détecter les communautés parmi les personnages de Games of Thrones. Vous devez utiliser les csv de nodes et de edges pour cela. \n",
    "\n",
    "Cet algorithme consiste à propager les étiquettes dans le réseau selon une règle d'évaluation optimisant la modularité du réseau. Lorsque l'algorithme atteint un optimum local, il regarde s'il peut combiner deux communautés pour augmenter la modularité du réseau. L'algorithme choisit toujours la combinaison la plus avantageuse. Si une combinaison est trouvée, la propagation des étiquettes est refaite. L'algorithme continue tant qu'elle peut améliorer la modularité. Vous pouvez lire l'article mentionné plus haut pour plus de détails, mais cela n'est pas nécessaire puisque vous allez être guidé tout le long du TP. \n",
    "\n",
    "Pour faciliter la représentation du réseau, nous vous proposons d'utiliser le package networkx. Vous pouvez lire plus sur le package [ici](https://networkx.github.io/documentation/stable/tutorial.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vous pouvez bien sûr utiliser anaconda pour installer les packages\n",
    "!pip install --user numpy\n",
    "!pip install --user pandas\n",
    "!pip install --user matplotlib\n",
    "!pip install --user networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import random\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "\n",
    "class LPAmPlus:\n",
    "    \"\"\"\n",
    "    Contructeur\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, graph):\n",
    "        \"\"\"\n",
    "        graph donne le graph sur lequel l'algoritme va être appliqué;\n",
    "        \"\"\"\n",
    "        self.graph = graph\n",
    "\n",
    "        \"\"\"\n",
    "        labels donne l'ensemble des communautés présentes dans le réseau\n",
    "        \"\"\"\n",
    "        self.labels = None\n",
    "\n",
    "        \"\"\"\n",
    "        Assigner une étiquette à chaque sommet\n",
    "        \"\"\"\n",
    "        #TODO\n",
    "\n",
    "    \"\"\"\n",
    "    Terme à optimiser lors du remplacement des étiquettes\n",
    "    \"\"\"\n",
    "\n",
    "    def label_evaluation(self, current_node, new_label):\n",
    "        #TODO\n",
    "        return 0\n",
    "\n",
    "    \"\"\"\n",
    "    Fonction pour le remplacement d'étiquette\n",
    "    \"\"\"\n",
    "\n",
    "    def update_label(self, current_node):\n",
    "        return False\n",
    "\n",
    "    \"\"\"\n",
    "    Fonction qui calcule la modularité actuelle du réseau\n",
    "    \"\"\"\n",
    "\n",
    "    def modularity(self):\n",
    "        #TODO\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Fonction qui applique l'algorithme LPAm sur le réseau\n",
    "    \"\"\"\n",
    "\n",
    "    def LPAm(self):\n",
    "        #TODO\n",
    "   \n",
    "    \"\"\"\n",
    "    Fonction qui trouve les deux communautés à combiner et les combine\n",
    "    \"\"\"\n",
    "    def merge_communities(self):\n",
    "        #TODO\n",
    "        return False\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Fonction qui applique LPAm+ sur le réseau\n",
    "    \"\"\"\n",
    "\n",
    "    def find_communities(self):\n",
    "        #TODO\n",
    "\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yv83c1sWXGzq"
   },
   "source": [
    "### 1.1 Dataset (1 point)\n",
    "\n",
    "Nous vous avons fourni les csv pour toutes les saisons de Games of Thrones. Vous devez maintenant représenter ces réseaux en code en utilisant les deux csv fournis pour chaque saison: un pour les sommets et un pour les arêtes. \n",
    "\n",
    "\n",
    "#### Implémentation\n",
    "1. Implémentez  la fonction  *`load_unweighted_network`*. Cette fonction retourne le réseau non dirigé et sans poids.\n",
    "\n",
    "Utilisez la fonction `test_load` pour vérifier votre implémentation de la fonction. Ce test utilise un petit toy dataset. Vous devriez avoir quelque chose de similaire:\n",
    "![title](data/picture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "def load_unweighted_network(node_csv, edge_csv):\n",
    "    #TODO\n",
    "    \n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 607,
     "status": "ok",
     "timestamp": 1572273158769,
     "user": {
      "displayName": "Kim Thuyen Ton",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBg1xy2-8526x-b1HLCbT16SZlMsjmtKfyoHRgghw=s64",
      "userId": "10674693358177584608"
     },
     "user_tz": 240
    },
    "id": "HEwBsNVsjvfs",
    "outputId": "aedf1752-21aa-49b8-e31b-8892f3f5e2e6"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def test_load():\n",
    "    network = load_unweighted_network(\"data/toy-nodes.csv\", \"data/toy-edges.csv\")\n",
    "    nx.draw_networkx(network,font_color='white')\n",
    "    plt.show()\n",
    "\n",
    "test_load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6UTIxaGIXGzz"
   },
   "source": [
    "### 1.2  Modularité (1 point)\n",
    "\n",
    "La modularité $Q$ du réseau est une mesure importante pour l'algorithme. Elle permet de savoir si l'algorithme a atteint un optimum local ou pas. $$ Q=\\frac{1}{2m}\\sum_{u,v=1}^n B_{uv}\\delta(l_u,l_v)$$ \n",
    "\n",
    "- m: le nombre d'arêtes\n",
    "- l: l'étiquette du sommet\n",
    "- u, v: des sommets dans le réseau\n",
    "- B: la matrice de modularité où chaque élément vaut $A_{uv} - P_{uv}$\n",
    "- $A_{uv}$: vaut 1 si il y une arête entre u et v sinon 0\n",
    "- $P_{uv}$: la probabilité qu'il y ait une arête entre u et v selon le modèle nul  $$P_{uv}=\\frac{degree(u)*degree(x)}{2m}$$\n",
    "- $\\delta(l_u,l_v)$: delta de Kronecker, vaut 1 si les deux labels sont identiques sinon 0\n",
    "\n",
    "Elle peut aussi être définie comme: $$Q=\\sum_{t=1}^{N_c}\\left(\\frac{I_t}{m}-\\left(\\frac{D_t}{2m}\\right)^2\\right)$$\n",
    "\n",
    "- m: le nombre d'arêtes\n",
    "- Nc: le nombre de communautés\n",
    "- t: une communauté dans le réseau\n",
    "- $I_t$: le nombre d'arêtes dans la communauté t c'est-à-dire que les deux sommets de l'arête appartiennent à t\n",
    "- $D_t$: la somme des degrés de tous les sommets appartenant à t\n",
    "\n",
    "#### Implémentation\n",
    "1. Implémentez  la fonction  `modularity`  dans LPAmPlus. Cette fonction retourne la modularité du réseau. Vous pouvez utiliser la fonction `linalg.modularity_matrix` de networkx pour calculer la matrice B. Prenez la définition présentée que vous voulez. **N.B:** Networkx permet d'ajouter du data sur les sommets pour garder des informations sur le node.\n",
    "\n",
    "Utilisez la fonction `test_modularity` pour vérifier votre implémentation de la fonction. Vous devriez obtenir une modularité d'environ 0.413."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_modularity():\n",
    "    social_network = load_unweighted_network(\"data/toy-nodes.csv\", \"data/toy-edges.csv\")\n",
    "    lpam = LPAmPlus(social_network)\n",
    "    lpam.labels = [0, 1]\n",
    "    for i in [0,1,2,3,4,5,6,7,8,9]:\n",
    "        lpam.graph.nodes[i]['label'] = 0\n",
    "    for i in [10,11,12,13,14,15]:\n",
    "        lpam.graph.nodes[i]['label'] = 1\n",
    "    print(\"Modularity: {}\".format(lpam.modularity()))\n",
    "\n",
    "test_modularity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vwxvqYj4XGzu"
   },
   "source": [
    "### 1.3 Règle de modification des étiquettes (2 points)\n",
    "\n",
    "Comme mentionné plus haut, l'algorithme est fortement basé sur son optimisation de la modularité. Il vous est maintenant demandé d'implémenter le terme à optimiser. La nouvelle étiquette $l_x^{new}$ correspond à l'étiquette pour laquelle la somme donne la plus grande valeur.\n",
    "$$l_x^{new}=\\arg\\max\\sum_{u=1}^n B_{ux}\\delta(l_u,l)$$\n",
    "\n",
    "- n: le nombre de sommets\n",
    "- m: le nombre d'arêtes\n",
    "- l: l'étiquette du sommet\n",
    "- x: le sommet qu'on évalue en ce moment\n",
    "- u: un autre sommet dans le réseau (commence à 1, car on exclut le sommet x)\n",
    "- B: la matrice de modularité où chaque élément vaut $A_{ux} - P_{ux}$\n",
    "- $A_{ux}$: vaut 1 si il y une arête entre u et x sinon 0\n",
    "- $P_{ux}$: la probabilité qu'il y ait une arête entre u et x selon le modèle nul  $$P_{ux}=\\frac{degree(u)*degree(x)}{2m}$$\n",
    "- $\\delta(l_u,l)$: delta de Kronecker, vaut 1 si les deux labels sont identiques sinon 0\n",
    "\n",
    "\n",
    "#### Implémentation\n",
    "1. Implémenter la fonction `label_evaluation`. Cette fonction retourne la valeur du terme à optimiser. Vous pouvez utiliser la fonction `linalg.modularity_matrix` de networkx pour calculer la matrice B. Il est normal qu'il y ait une ressemblance avec le calcul de la modularité selon la définition que vous avez prise.\n",
    "2. Implémenter la fonction `update_label`. Cette fonction choisit la nouvelle étiquette pour le sommet actuel. En cas d'égalité, la fonction choisit une étiquette au hasard parmi les meilleurs. N'oubliez pas d'enlever les étiquettes désuètes du paramètre `labels`. **N.B:** Networkx permet d'ajouter du data sur les sommets pour garder des informations sur le node.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g5_N31uPXGz2"
   },
   "source": [
    "### 1.4 LPAm (3 points)\n",
    "\n",
    "Vous pouvez maintenant implémenter l'algorithme LPAm. Cet algorithme est le prédécesseur de LPAm+. Il commence par donner une étiquette unique à chaque sommet. Il explore par la suite tous les sommets et change leur étiquette selon la fonction d'évaluation que vous avez implémentée plus tôt. L'algorithme continue jusqu'il ne puisse plus améliorer la modularité du réseau.\n",
    "\n",
    "#### Implémentation\n",
    "1. Initialiser correctement le paramètre `labels` de LPAmPlus et ajouter les étiquettes aux sommets du graphe dans la fonction `__init__`.\n",
    "\n",
    "2. Implémenter l'algorithme LPAm dans la fonction `LPAm`. Assurez-vous de toujours augmenter la modularité lors de vos changements d'étiquettes.\n",
    "\n",
    "Utilisez la fonction `test_lpam` pour vérifier votre implémentation. Vous devriez finir avec une modularité d'environ 0.399 avec 4 communautés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lpam():\n",
    "    social_network = load_unweighted_network(\"data/toy-nodes.csv\", \"data/toy-edges.csv\")\n",
    "    lpam = LPAmPlus(social_network)\n",
    "    lpam.LPAm()\n",
    "    print(\"Modularity: {}\\nCommunities: {}\".format(lpam.modularity(), lpam.labels))\n",
    "\n",
    "test_lpam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cj5Ghd5jXGz6"
   },
   "source": [
    "### 1.5 LPAm+ (2 point)\n",
    "\n",
    "Vous pouvez maintenant implémenter LPAm+ au complet. Lorsque LPAm tombe dans un optimum local, LPAm+ essaye de combiner deux communautés pour augmenter la modularité. LPAm+ choisit la combinaison qui augmente le plus la modularité et recommence la propagation d'étiquette jusqu'au prochain optimum local. L'algorithme continue jusqu'à qu'il ne peut plus augmenter la modularité.\n",
    "\n",
    "#### Implémentation\n",
    "1. Implémentez  la fonction  `merge_communities`. Cette fonction regarde si combiner des communautés augmente la modularité et combine les meilleurs choix. Elle retourne True si une combinaison a été faite sinon False.\n",
    "2. Implémenter `find_communities`. Cette fonction applique l'algorithme LPAm+ sur le réseau.\n",
    "\n",
    "Utilisez la fonction `test_lpam_plus` pour vérifier votre implémentation. Vous devriez finir avec une modularité d'environ 0.413 et 2 communautés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lpam_plus():\n",
    "    social_network = load_unweighted_network(\"data/toy-nodes.csv\", \"data/toy-edges.csv\")\n",
    "    lpam = LPAmPlus(social_network)\n",
    "    lpam.find_communities()\n",
    "    print(\"Modularity: {}\\nCommunities: {}\".format(lpam.modularity(), lpam.labels))\n",
    "\n",
    "test_lpam_plus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vODCJbRaXGz-"
   },
   "source": [
    "### 1.6 GOT dataset (4 points)\n",
    "\n",
    "Rouler votre algorithme sur les données de Games of Thrones de chaque saison et comparer ce que vous obtenez et les vraies communautés. \n",
    "\n",
    "Commencez par calculer le ARI (ajusted Rand index) de vos résultats. $$ ARI=\\frac{TP+TN}{TP+TN+FN+TN} = \\frac{TP+TN}{\\binom{n}{2}}$$\n",
    "\n",
    "- n: le nombre de sommets\n",
    "- TP: True positive soit le nombre de paires d'éléments qui se trouvent dans la même communauté dans vos résultats et dans le ground truth\n",
    "- TN: True négative soit le nombre de paires d'éléments qui se trouvent dans des communautés différentes dans vos résultats et dans le ground truth\n",
    "- FP: False positive soit le nombre de paires d'éléments qui se trouvent dans la même communauté dans vos résultats mais qui sont dans des communautés différentes dans le ground truth\n",
    "- FN: False négative soit le nombre de paires d'éléments qui se trouvent dans des communautés différentes alors qu'ils sont dans la même communauté dans le ground truth\n",
    "\n",
    "\n",
    "L'algorithme performe-t-il bien sur toutes les saisons ou pour certaines seulement? Expliquer pourquoi vous avez obtenu ces résultats. Vous pouvez faire les manipulations que vous voulez pour mieux présenter vos résultats et mieux appuyer vos affirmations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1-2UipMRXG0R"
   },
   "outputs": [],
   "source": [
    "# Mettez votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse\n",
    "Écrivez votre analyse ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r3FmllqgXG0d"
   },
   "source": [
    "# 2. Personnages influents dans GOT (8 points)\n",
    "\n",
    "##  Analyse d'un réseau social \n",
    "Une autre analyse intéressante à faire avec un réseau social est de trouver les personnes influentes du réseau soit les personnes autour desquelles les gens du réseau se regroupent.\n",
    "\n",
    "Il existe des mesures qui permettent de connaître ces personnes: les mesures de centralité. Pour vous aider lors de l'implémentation de ses mesures, un deuxième toy dataset vous est fourni. Il ressemble à ceci:\n",
    "![title](data/picture2.png)\n",
    "\n",
    "## GOT datasets\n",
    "La série Games of Thrones est reconnue pour tuer ses personnages importants. Nous vous demandons de vérifier cette affirmation. Pour cette partie, vous devez utiliser tous les csv donnés avec le TP (nodes, edges et deaths). Nous voulons que vous trouviez les personnages les plus influents de chaque saison et que vous les compariez avec la liste de personnages morts durant la saison.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uJxSGCnOXG0e"
   },
   "source": [
    "## 2.1 Centralité de degré (1 point)\n",
    "\n",
    "Une première mesure simple pour trouver l'importance d'un sommet dans un réseau est la centralité de degré. Elle se calcule $$C_{D}(i) = \\frac{degree(i)}{n-1}$$\n",
    "\n",
    "- i: un sommet dans le réseau\n",
    "- n: le nombre de sommets\n",
    "- degree: le nombre d'arêtes attachées au sommet\n",
    "\n",
    "#### Implémentation\n",
    "1. Implémenter la fonction `calculate_degree_centrality`. Cette fonction calcule la centralité de degré pour tous les sommets du réseau et ajoute cette mesure à chaque sommet.\n",
    "\n",
    "Utilisez la fonction `test_degree_centrality` pour vérifier votre implémentation. Le sommet 1 devrait avoir la plus haute mesure de 0.4375."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_degree_centrality(social_network):\n",
    "    #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_degree_centrality():\n",
    "    social_network = load_unweighted_network(\"data/toy-nodes2.csv\", \"data/toy-edges2.csv\")\n",
    "    calculate_degree_centrality(social_network)\n",
    "    dict_centrality = nx.get_node_attributes(social_network, 'degree_centrality')\n",
    "    best_node = max(dict_centrality, key=dict_centrality.get)\n",
    "    print(\"Highest degree centrality node: {} with {}\".format(best_node, dict_centrality[best_node]))\n",
    "test_degree_centrality()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uJxSGCnOXG0e"
   },
   "source": [
    "## 2.2 Centralité de proximité (1 point)\n",
    "\n",
    "Une autre mesure simple pour trouver l'importance d'un sommet dans un réseau est la centralité de proximité. Elle se calcule $$C_{P}(i) = \\frac{1}{AvDist(i)}$$\n",
    "\n",
    "- i: un sommet dans le réseau\n",
    "- AvDist: la moyenne de toutes les distances les plus courtes pour atteindre chaque sommet à partir du sommet i\n",
    "\n",
    "#### Implémentation\n",
    "1. Implémenter la fonction `calculate_closeness_centrality`. Cette fonction calcule la centralité de proximité pour tous les sommets du réseau et ajoute cette mesure à chaque sommet. Considérer chaque arête comme une distance de 1.\n",
    "\n",
    "**NB**: Utiliser la fonction `shortest_path()` du module Networkx pour trouver le chemin le plus court entre des sommets\n",
    "\n",
    "Utilisez la fonction `test_closeness_centrality` pour vérifier votre implémentation. Le sommet 3 devrait avoir la plus haute mesure de 0.41."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_closeness_centrality(social_network):\n",
    "    #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_closeness_centrality():\n",
    "    social_network = load_unweighted_network(\"data/toy-nodes2.csv\", \"data/toy-edges2.csv\")\n",
    "    calculate_closeness_centrality(social_network)\n",
    "    dict_centrality = nx.get_node_attributes(social_network, 'closeness_centrality')\n",
    "    best_node = max(dict_centrality, key=dict_centrality.get)\n",
    "    print(\"Highest closeness centrality node: {} with {}\".format(best_node, dict_centrality[best_node]))\n",
    "\n",
    "test_closeness_centrality()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uJxSGCnOXG0e"
   },
   "source": [
    "## 2.3 Centralité d'intermédiarité (2 points)\n",
    "\n",
    "Une dernière mesure simple pour trouver l'importance d'un sommet dans un réseau est la centralité d'intermédiarité. Elle se calcule $$C_{I}(i) = \\frac{\\sum_{j<k}f_{jk}(i)}{\\binom{n}{2}}$$\n",
    "\n",
    "- n: le nombre de sommets dans le réseau\n",
    "- i: un sommet dans le réseau\n",
    "- j,k: deux sommets dans le réseau excluant i\n",
    "- $f_{jk}(i)$: le nombre de chemin le plus court partant du sommet j vers un sommet k (> j) passant par le sommet i \n",
    "\n",
    "#### Implémentation\n",
    "1. Implémenter la fonction `calculate_betweenness_centrality`. Cette fonction calcule la centralité d'intermédiarité pour tous les sommets du réseau et ajoute cette mesure à chaque sommet.\n",
    "\n",
    "Utilisez la fonction `test_betweennes_centrality` pour vérifier votre implémentation. Le sommet 4 devrait avoir la plus haute mesure de 0.57."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_betweenness_centrality(social_network):\n",
    "    #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_betweenness_centrality():\n",
    "    social_network = load_unweighted_network(\"data/toy-nodes2.csv\", \"data/toy-edges2.csv\")\n",
    "    calculate_betweenness_centrality(social_network)\n",
    "    dict_centrality = nx.get_node_attributes(social_network, 'betweenness_centrality')\n",
    "    best_node = max(dict_centrality, key=dict_centrality.get)\n",
    "    print(\"Highest betweenness centrality node: {} with {}\".format(best_node, dict_centrality[best_node]))\n",
    "\n",
    "test_betweenness_centrality()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "996_M0-sXG0w"
   },
   "source": [
    "## 2.4 Analyse de vos résultats (4 points)\n",
    "\n",
    "Roulez les trois fonctions sur les réseaux de chaque saison et présentez le top 10 pour chaque mesure. Pour chaque saison, comparez le top 10 des mesures avec la liste de morts de la saison. Est-ce que le top 10 est suffisant pour trouver les morts importants de chaque saison? Quelle mesure semble mieux prédire les morts? Est-ce que la réputation de Games of Thrones de tuer ses personnages importants est fondée?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mettez le code pour présenter les résultats ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s2U3Xs73-rDr"
   },
   "source": [
    "### Analyse\n",
    "\n",
    "Écrivez ici"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TP3_INF8215.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
